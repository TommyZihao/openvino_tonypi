{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ea5f6d-51c6-4eaf-967d-3c80efc8f0f6",
   "metadata": {},
   "source": [
    "# 三行代码开启大模型对话\n",
    "\n",
    "同济子豪兄 2024-9-3\n",
    "\n",
    "在酷睿Ultra处理器的AIPC轻薄笔记本电脑上，基于OpenVINO本地端侧部署Qwen2-7B-Instruct开源大模型。实现和大模型的人机对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e490cd-9a3b-4c0b-a6ad-9e558fde18cf",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546ef441-653b-41fb-a2e7-5233545d6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai as ov_genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c445d-506b-4759-acfe-60b782470bf1",
   "metadata": {},
   "source": [
    "## 选择计算设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63accc84-6bf5-4106-9475-2dad78f12384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'CPU'\n",
    "device = 'GPU'\n",
    "# device = 'NPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706868c1-9b32-4a4c-969a-d652698e1ab9",
   "metadata": {},
   "source": [
    "## 载入OpenVINO IR格式的大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4779649-9a64-4daa-a64c-a7eb6183fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ov_genai.LLMPipeline(\"Qwen2-7B-Instruct-int4-ov\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704a788-debf-499c-9f5e-979ebbb42b94",
   "metadata": {},
   "source": [
    "## 提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cb588a-751e-44b9-9947-fd7ea84161e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n什么是OpenVINO？<|im_end|>\\n<|im_start|>assistant\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4febbd3-7daf-4bb4-9e5c-4446ee7726fb",
   "metadata": {},
   "source": [
    "## 大模型推理预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f87a4c-0d5b-432a-91f6-35a1de80ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0ecaa1-49b6-4c9d-a259-43e0e39aeb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一种高效的方式来运行神经网络，特别是针对视觉任务，如图像和视频处理。\\n\\nOpenVINO的主要功能包括：\\n\\n1. **模型优化**：它能够优化神经网络模型，以便在不同的硬件平台上高效运行。这包括对模型进行剪枝、量化和转换，以减少计算和内存需求。\\n\\n2. **运行时引擎**：OpenVINO提供了一个高性能的运行时引擎，可以将优化后的模型部署到各种硬件上，包括CPU、GPU、VPU（视觉处理单元）等。\\n\\n3. **API支持**：它提供了多种编程接口，如C++、Python、MATLAB等，使得开发者可以轻松地将模型集成到自己的应用程序中。\\n\\n4. **跨平台支持**：OpenVINO支持多种操作系统和硬件平台，包括Windows、Linux、Mac OS等，以及各种类型的处理器和加速器。\\n\\n5. **推理工具**：它包括一系列工具，用于评估模型性能、优化模型、生成可移植的模型等。\\n\\nOpenVINO广泛应用于各种领域，如自动驾驶、安防监控、机器人、医疗影像分析等，帮助开发者快速构建和部署高性能的视觉和深度学习应用。']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6a9c70-4185-40da-b479-799cba8f8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一种高效的方式来运行神经网络，特别是针对视觉任务，如图像和视频处理。\n",
      "\n",
      "OpenVINO的主要功能包括：\n",
      "\n",
      "1. **模型优化**：它能够优化神经网络模型，以便在不同的硬件平台上高效运行。这包括对模型进行剪枝、量化和转换，以减少计算和内存需求。\n",
      "\n",
      "2. **运行时引擎**：OpenVINO提供了一个高性能的运行时引擎，可以将优化后的模型部署到各种硬件上，包括CPU、GPU、VPU（视觉处理单元）等。\n",
      "\n",
      "3. **API支持**：它提供了多种编程接口，如C++、Python、MATLAB等，使得开发者可以轻松地将模型集成到自己的应用程序中。\n",
      "\n",
      "4. **跨平台支持**：OpenVINO支持多种操作系统和硬件平台，包括Windows、Linux、Mac OS等，以及各种类型的处理器和加速器。\n",
      "\n",
      "5. **推理工具**：它包括一系列工具，用于评估模型性能、优化模型、生成可移植的模型等。\n",
      "\n",
      "OpenVINO广泛应用于各种领域，如自动驾驶、安防监控、机器人、医疗影像分析等，帮助开发者快速构建和部署高性能的视觉和深度学习应用。\n"
     ]
    }
   ],
   "source": [
    "print(result.texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6037a0f7-6b0b-4163-847a-4b36a15e0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以加推理参数和 stop flag\n",
    "\n",
    "# def streamer(subword):\n",
    "#     print(subword, end='', flush=True)\n",
    "#     return False\n",
    "\n",
    "# result = pipe.generate(prompt, eos_token_id=151645, max_length=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c218bf-68db-409d-81d6-afb1a00d3b8a",
   "metadata": {},
   "source": [
    "## 函数：大模型对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b72fb23-2f26-4ca6-91eb-1972dcce4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_qwen_ov(question=\"什么是OpenVINO？\"):\n",
    "    prompt = \"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n{}<|im_end|>\\n<|im_start|>assistant\\n\".format(question)\n",
    "    result = pipe.generate(prompt)\n",
    "    return result.texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84f7247-9b6f-48ad-8da4-c15ce5bbc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat_qwen_ov('什么是OpenVINO？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab78d669-3283-4935-b4e0-24d801c4e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一种高效的方式来运行神经网络，特别是针对计算机视觉任务。\n",
      "\n",
      "OpenVINO的主要功能包括：\n",
      "\n",
      "1. **模型优化**：它能够优化神经网络模型，以便在不同的硬件平台上高效运行。这包括对模型进行剪枝、量化和转换，以减少模型大小和运行时间。\n",
      "\n",
      "2. **运行时引擎**：OpenVINO提供了一个高性能的运行时引擎，用于在各种硬件平台上执行优化后的模型。这包括CPU、GPU、VPU（英特尔视觉处理器单元）等。\n",
      "\n",
      "3. **API支持**：它提供了多种编程接口，如C++、Python、MATLAB等，使得开发者可以轻松地将优化后的模型集成到自己的应用程序中。\n",
      "\n",
      "4. **模型库**：OpenVINO还包含了一些预训练的模型库，开发者可以直接使用这些模型进行各种计算机视觉任务，如物体检测、图像分类、目标识别等。\n",
      "\n",
      "5. **支持多种硬件平台**：它支持多种硬件平台，包括英特尔的各种处理器和加速器，以及一些常见的开源硬件平台。\n",
      "\n",
      "通过使用OpenVINO，开发者可以加速深度学习模型的部署过程，提高模型在实际应用中的性能，同时减少开发和部署的复杂性。\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4869f68-2455-4f37-97ac-94c0cb712283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
